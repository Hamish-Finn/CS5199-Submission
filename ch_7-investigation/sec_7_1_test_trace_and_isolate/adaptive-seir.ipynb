{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Adaptive SEIR: Trace, Test and Isolate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epyc import JSONLabNotebook, ParallelLab\n",
    "import epyc\n",
    "import epydemic\n",
    "import numpy as np\n",
    "from epydemic import SEIR, SIR, ERNetwork, Monitor, ProcessSequence, rng, SynchronousDynamics\n",
    "import matplotlib.pyplot as plt\n",
    "from parameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data_output_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the Adaptive SEIR model\n",
    "\n",
    "This Adaptive SEIR model will run simulations until model equilibrium. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below was taken from a GitHub repo by Simon Dobson at https://github.com/simoninireland/introduction-to-epidemics/blob/master/src/seir.ipynb (last accessed 2023-11-09) \n",
    "# BEGIN Copied Code\n",
    "class AdaptiveSEIR(SEIR):\n",
    "    P_DETECT = 'pDetect'  #: Parameter for the probability of detecting an exposed neighbour of an infected node.\n",
    "    P_REWIRE = 'pRewire'  #: Parameter for the probability of rewiring an SE or SI edge.\n",
    "\n",
    "    DEFAULT_EQUILIBRIUM_STEM = SEIR.REMOVED + \".at.default.equilibrium\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AdaptiveSEIR, self).__init__()\n",
    "        self._pDetect = None\n",
    "        self._pRewire = None\n",
    "\n",
    "    def build(self, params):\n",
    "        super(AdaptiveSEIR, self).build(params)\n",
    "\n",
    "        # store the parameters for later\n",
    "        self._pDetect = params[self.P_DETECT]\n",
    "        self._pRewire = params[self.P_REWIRE]\n",
    "\n",
    "        self.trackNodesInCompartment(epydemic.SEIR.SUSCEPTIBLE)\n",
    "        self.trackNodesInCompartment(epydemic.SEIR.REMOVED)\n",
    "\n",
    "\n",
    "    def quarantine(self, n):\n",
    "        g = self.network()\n",
    "        rng = np.random.default_rng()\n",
    "        ms = list(g.neighbors(n))\n",
    "        for m in ms:\n",
    "            if self.getCompartment(m) == self.SUSCEPTIBLE and rng.random() <= self._pRewire:\n",
    "                # a susceptible neighbour, remove link to us\n",
    "                self.removeEdge(n, m)\n",
    "\n",
    "                # rewire to another random susceptible\n",
    "                mprime = self.locus(self.SUSCEPTIBLE).draw()\n",
    "                self.addEdge(m, mprime)\n",
    "\n",
    "    def symptoms(self, t, n):\n",
    "        # perform a normal becoming-symptomatic event\n",
    "        super(AdaptiveSEIR, self).symptoms(t, n)\n",
    "\n",
    "        g = self.network()\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "        # examine all neighbours and look for exposed\n",
    "        # nodes to quarantine\n",
    "        ms = list(g.neighbors(n))\n",
    "        for m in ms:\n",
    "            if self.getCompartment(m) == self.EXPOSED and rng.random() <= self._pDetect:\n",
    "                # detected an exposed individual,\n",
    "                # quarantine them\n",
    "                self.quarantine(m)\n",
    "\n",
    "        # quarantine the newly symptomatic node\n",
    "        self.quarantine(n)\n",
    "# END Copied Code\n",
    "\n",
    "    # Override the default atEquilibrium function to end a simulation once the model reaches equilibrium.\n",
    "    def atEquilibrium(self, t):\n",
    "        # For SEIR models, equilibrium is reached when there are no more infected or exposed nodes, thus no more infection, removal or symptoms events.\n",
    "        return len(self.compartment(self.INFECTED)) == 0 and len(self.compartment(self.EXPOSED)) == 0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define an ASEIR monitor to capture the number of removed nodes of the SEIR process at defined simulation timepoints.\n",
    "Note that the Monitor class is overridden to try and reduce the memory footprint of the simulation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASEIR_Monitor(Monitor):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def observe(self, t, e):\n",
    "        '''Observe the network, capturing the sizes of all loci which are then\n",
    "        stored into individual time series. Another time series,\n",
    "        tagged :attr:`OBSERVATIONS`, is created to store the sequence\n",
    "        of times at which observations were made.\n",
    "\n",
    "        :param t: the current simulation time\n",
    "        :param e: the element (ignored)\n",
    "\n",
    "        '''\n",
    "        n = self.dynamics().locus(SEIR.REMOVED).name()\n",
    "        l = self.dynamics().locus(SEIR.REMOVED)\n",
    "\n",
    "        # if this is the first run, build the initial dicts: one\n",
    "        # per locus and one for the observation times\n",
    "        # (We can't do this as part of build() as it depends on which\n",
    "        # other processes we're composed with, and in what order)\n",
    "        if self._timeSeries is None:\n",
    "            self._timeSeries = dict()\n",
    "            self._timeSeries[self.OBSERVATIONS] = []\n",
    "            self._timeSeries[Monitor.timeSeriesForLocus(n)] = []\n",
    "\n",
    "\n",
    "        # make the observation\n",
    "        self._timeSeries[self.OBSERVATIONS].append(t)\n",
    "        self._timeSeries[Monitor.timeSeriesForLocus(n)].append(len(l))\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define an epyc experiment to run the SEIR model with the defined parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex_1_seir(lab):\n",
    "    # set the disease parameter space\n",
    "    lab[AdaptiveSEIR.P_EXPOSED] = p_exposed\n",
    "    lab[AdaptiveSEIR.P_INFECT_ASYMPTOMATIC] = p_infect\n",
    "    lab[AdaptiveSEIR.P_INFECT_SYMPTOMATIC] = p_infect\n",
    "    lab[SEIR.P_REMOVE] = p_remove\n",
    "    lab[SEIR.P_SYMPTOMS] = p_remove\n",
    "        \n",
    "    lab[AdaptiveSEIR.P_REWIRE] = p_rewire\n",
    "    lab[AdaptiveSEIR.P_DETECT] = p_detect\n",
    "\n",
    "    # setup the monitor to capture the state of the simulation at the defult timeout. \n",
    "    lab[epydemic.Monitor.DELTA] = AdaptiveSEIR.DEFAULT_MAX_TIME\n",
    "\n",
    "    lab['ens'] = range(ens)\n",
    "\n",
    "    # set the topology for the generated network\n",
    "    lab[ERNetwork.N] = n\n",
    "    lab[ERNetwork.KMEAN] = k_mean\n",
    "\n",
    "    # create the model, network generator, and experiment\n",
    "    p = ProcessSequence([AdaptiveSEIR(), ASEIR_Monitor()])\n",
    "    g = ERNetwork()\n",
    "    e = epydemic.StochasticDynamics(p, g)\n",
    "\n",
    "    # run the experiment\n",
    "    lab.runExperiment(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run the experiment in parallel with the defined parameters.\n",
    "\n",
    "Note that the controlled variable is partitioned into 100 values, and each value is run in a separate process. This aims to reduce the memory footprint of the simulation by writing the results to disk after each pdetect increment. Furthermore, this reduces memory loss in the event of a crash.\n",
    "\n",
    "Additioanly the ensemble size is halved to reduce the memory footprint of the simulation, each set of repeats is written to a separate file. This data is then combined to perform analysis with an appropriate ensemble size."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the controlled variables.\n",
    "pds = np.split(p_detect, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ens = ens / 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First set of 50 experiement repeats."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the parallel lab.\n",
    "lab = ParallelLab(JSONLabNotebook(get_out_path(\"ex_1_seir\"), create=True), cores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To minimise memory usage, run the experiment in parallel with a single p_detect value per process.\n",
    "for i, pd in enumerate(pds):\n",
    "    p_detect = pd\n",
    "    lab.createWith(\"ex_\" + str(i), ex_1_seir)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Second set of experiement repeats."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lab = ParallelLab(JSONLabNotebook(get_out_path(\"ex_2_seir\"), create=True), cores)\n",
    "\n",
    "for i, pd in enumerate(pds):\n",
    "    p_detect = pd\n",
    "    lab.createWith(\"ex_\" + str(i), ex_1_seir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Further experiement to collect the point of equilibrium for each simulation.\n",
    "\n",
    "Note that this experiment does not use the Monitor class, as this process will run the simulation until the default timeout to record the outbreak size at that point. However, this approach does not capture the equilibrium time for simulations that reach equilibrium before the timeout. Therefore, the simulation will be repeated, but only the time it takes for each simulation to reach equilibrium will be recorded."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ex_1_seir(lab):\n",
    "    # set the disease parameter space\n",
    "    lab[AdaptiveSEIR.P_EXPOSED] = p_exposed\n",
    "    lab[AdaptiveSEIR.P_INFECT_ASYMPTOMATIC] = p_infect\n",
    "    lab[AdaptiveSEIR.P_INFECT_SYMPTOMATIC] = p_infect\n",
    "    lab[SEIR.P_REMOVE] = p_remove\n",
    "    lab[SEIR.P_SYMPTOMS] = p_remove\n",
    "        \n",
    "    lab[AdaptiveSEIR.P_REWIRE] = p_rewire\n",
    "    lab[AdaptiveSEIR.P_DETECT] = p_detect\n",
    "\n",
    "    lab['ens'] = range(ens)\n",
    "\n",
    "    # set the topology for the generated network\n",
    "    lab[ERNetwork.N] = n\n",
    "    lab[ERNetwork.KMEAN] = k_mean\n",
    "\n",
    "    # create the model, network generator, and experiment\n",
    "    p = AdaptiveSEIR()\n",
    "    g = ERNetwork()\n",
    "    e = epydemic.StochasticDynamics(p, g)\n",
    "\n",
    "    # run the experiment\n",
    "    lab.runExperiment(e)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run experiments to collect the equilibrium time for each simulation. Note a similar approach is used to reduce the memory footprint of the simulation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lab = ParallelLab(JSONLabNotebook(get_out_path(\"ex_3_seir\"), create=True), cores)\n",
    "\n",
    "for i, pd in enumerate(pds):\n",
    "    p_detect = pd\n",
    "    lab.createWith(\"ex_\" + str(i), ex_1_seir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lab = ParallelLab(JSONLabNotebook(get_out_path(\"ex_4_seir\"), create=True), cores)\n",
    "\n",
    "for i, pd in enumerate(pds):\n",
    "    p_detect = pd\n",
    "    lab.createWith(\"ex_\" + str(i), ex_1_seir)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
